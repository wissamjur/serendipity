{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import pandas as pd\n",
    "\n",
    "# change dir for custom imports\n",
    "os.chdir('../')\n",
    "from scripts.dataset_downloader import initialize_dataset\n",
    "from scripts.k_means import create_clsuters, clustering_errors\n",
    "\n",
    "dataset = 'ml-100k'\n",
    "dataset_path = os.path.join('datasets', dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If dataset hasn't been previously initialized, it can be done with this function\n",
    "initialize_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_path = os.path.join(dataset_path, 'u.data')\n",
    "items_path = os.path.join(dataset_path, 'u.item')\n",
    "genres_path = os.path.join(dataset_path, 'u.genre')\n",
    "ratings_file = codecs.open(ratings_path, 'rU', 'UTF-8')\n",
    "items_file = codecs.open(items_path, 'rU', 'latin-1')\n",
    "\n",
    "# Load dfs\n",
    "ratings_df = pd.read_csv(ratings_file, sep='\\t', names=('user_id', 'item_id', 'rating', 'timestamp'))\n",
    "genres_df = pd.read_csv(genres_path, sep='|', names=('title', 'id'))\n",
    "cols_names = ('id', 'title', 'year', 'nan', 'link') + tuple(genres_df.title.to_list())\n",
    "items_df = pd.read_csv(items_file, sep='|', usecols=list(range(0,24)), names=cols_names).drop(columns=['nan', 'link'])\n",
    "\n",
    "# dataset stats\n",
    "print(f\"Total dataset users: {len(set(ratings_df.user_id.to_list()))}\")\n",
    "print(f\"Total dataset ratings: {len(ratings_df.user_id.to_list())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.merge(ratings_df, items_df, left_on='item_id', right_on='id')\\\n",
    "    .sort_values(by='user_id')\\\n",
    "    .drop(columns=['id', 'year', 'unknown', 'title', 'timestamp', 'item_id'])\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30  # total clusters\n",
    "clusters_df = create_clsuters(k, main_df)\n",
    "clusters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusters_df.groupby(['user_id', 'cluster']).size().reset_index(name='total_ratings')\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL - Elbow method for optimal k\n",
    "# Choose the range of k values to test.\n",
    "# We added a stride of 5 to improve performance. We don't need to calculate the error for every k value\n",
    "possible_k_values = range(2, 10, 5)\n",
    "\n",
    "# Calculate error values for all k values we're interested in\n",
    "errors_per_k = [clustering_errors(k, main_df) for k in possible_k_values]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "serendipity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
